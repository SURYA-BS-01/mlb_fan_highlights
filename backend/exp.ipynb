{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting polling...\n",
      "New data detected!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def fetch_schedule():\n",
    "    schedule_url = \"https://statsapi.mlb.com/api/v1/schedule?sportId=1&season=2024\"\n",
    "    response = requests.get(schedule_url)\n",
    "    return response.json()\n",
    "\n",
    "def detect_updates(current_data, new_data):\n",
    "    if current_data != new_data:\n",
    "        print(\"New data detected!\")\n",
    "        # Process the updated data here\n",
    "        return new_data\n",
    "    return current_data\n",
    "\n",
    "# Polling loop\n",
    "def start_polling(interval=60):  # Check every 60 seconds\n",
    "    print(\"Starting polling...\")\n",
    "    current_data = fetch_schedule()\n",
    "\n",
    "    while True:\n",
    "        time.sleep(interval)\n",
    "        try:\n",
    "            new_data = fetch_schedule()\n",
    "            new_data['new_data'] = \"New Data\"\n",
    "            current_data = detect_updates(current_data, new_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data: {e}\")\n",
    "\n",
    "start_polling()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import process_endpoint_url\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def initiate_data_ingestion(self):\n",
    "        game_pk = self.latest_completed_game()\n",
    "        game_data = self.get_single_game_data(game_pk)\n",
    "        return game_data\n",
    "\n",
    "    def latest_completed_game(self):\n",
    "        schedule_endpoint_url = 'https://statsapi.mlb.com/api/v1/schedule?sportId=1&season=2024'\n",
    "        \n",
    "        # Fetch schedule data\n",
    "        schedule_dates = process_endpoint_url(schedule_endpoint_url, \"dates\")\n",
    "\n",
    "        # Normalize games data into a DataFrame\n",
    "        games = pd.json_normalize(\n",
    "            schedule_dates.explode('games').reset_index(drop=True)['games']\n",
    "        )\n",
    "\n",
    "        date_columns = [\n",
    "            \"gameDate\",\n",
    "            \"officialDate\",\n",
    "            \"rescheduleDate\",\n",
    "            \"rescheduleGameDate\",\n",
    "            \"rescheduledFromDate\",\n",
    "            \"resumeDate\",\n",
    "            \"resumeGameDate\",\n",
    "            \"resumedFromDate\"\n",
    "        ]\n",
    "\n",
    "        # Convert the specified columns to datetime\n",
    "        for col in date_columns:\n",
    "            games[col] = pd.to_datetime(games[col], errors='coerce')\n",
    "\n",
    "        # Filter for completed games\n",
    "        completed_games = games[\n",
    "            games['status.detailedState'].isin(['Final', 'Completed Early'])\n",
    "        ]\n",
    "\n",
    "        # Get the most recent completed game\n",
    "        completed_games = completed_games.sort_values(by='gameDate', ascending=False)\n",
    "        latest_game = completed_games.iloc[0]\n",
    "\n",
    "        return latest_game['gamePk']\n",
    "    \n",
    "    \n",
    "    def get_single_game_data(self, game_pk):\n",
    "        single_game_feed_url = f'https://statsapi.mlb.com/api/v1.1/game/{game_pk}/feed/live'\n",
    "\n",
    "        single_game_info_json = json.loads(requests.get(single_game_feed_url).content)\n",
    "\n",
    "        return single_game_info_json\n",
    "    \n",
    "    def get_games_between_dates(self, start_date, end_date):\n",
    "        \"\"\"\n",
    "        Fetches all games and filters them between the specified start and end dates.\n",
    "\n",
    "        Args:\n",
    "            start_date (str): The start date in the format 'YYYY-MM-DD'.\n",
    "            end_date (str): The end date in the format 'YYYY-MM-DD'.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: A DataFrame containing games between the specified dates.\n",
    "        \"\"\"\n",
    "        schedule_endpoint_url = 'https://statsapi.mlb.com/api/v1/schedule?sportId=1&season=2024'\n",
    "\n",
    "        # Fetch all schedule data\n",
    "        schedule_dates = process_endpoint_url(schedule_endpoint_url, \"dates\")\n",
    "\n",
    "        # Normalize games data into a DataFrame\n",
    "        games = pd.json_normalize(\n",
    "            schedule_dates.explode('games').reset_index(drop=True)['games']\n",
    "        )\n",
    "\n",
    "        date_columns = [\n",
    "            \"gameDate\",\n",
    "            \"officialDate\",\n",
    "            \"rescheduleDate\",\n",
    "            \"rescheduleGameDate\",\n",
    "            \"rescheduledFromDate\",\n",
    "            \"resumeDate\",\n",
    "            \"resumeGameDate\",\n",
    "            \"resumedFromDate\"\n",
    "        ]\n",
    "\n",
    "        # Convert relevant columns to datetime\n",
    "        for col in date_columns:\n",
    "            games[col] = pd.to_datetime(games[col], errors='coerce')\n",
    "\n",
    "        # Filter games by 'gameDate' within the specified range\n",
    "        start_date = pd.to_datetime(start_date).tz_localize('UTC')\n",
    "        end_date = pd.to_datetime(end_date).tz_localize('UTC')\n",
    "\n",
    "        filtered_games = games[\n",
    "            (games['gameDate'] >= start_date) & (games['gameDate'] <= end_date)\n",
    "        ]\n",
    "\n",
    "        return filtered_games\n",
    "\n",
    "    \n",
    "\n",
    "data_ingestion = DataIngestion()\n",
    "\n",
    "# Get games between two dates\n",
    "start_date = '2024-04-01'\n",
    "end_date = '2024-04-04'\n",
    "games_between_dates = data_ingestion.get_games_between_dates(start_date, end_date)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-01 00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "start_date = pd.to_datetime(start_date).tz_localize('UTC')\n",
    "end_date = pd.to_datetime(end_date).tz_localize('UTC')\n",
    "print(start_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingestion = DataIngestion()\n",
    "game_data = data_ingestion.initiate_data_ingestion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-31T00:08:00Z\n"
     ]
    }
   ],
   "source": [
    "print((game_data[\"gameData\"][\"datetime\"][\"dateTime\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "print(pd.to_datetime(game_data[\"gameData\"][\"datetime\"][\"dateTime\"]).tz_convert('UTC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**GenAI, short for Generative AI, refers to a category of artificial intelligence algorithms and models that are designed to *generate* new content, rather than simply analyzing or acting upon existing data.**\\n\\nThink of traditional AI as being good at tasks like:\\n\\n* **Classification:** Identifying if an image is a cat or a dog.\\n* **Prediction:**  Predicting stock prices based on historical data.\\n* **Automation:**  Automating repetitive tasks based on predefined rules.\\n\\n**GenAI, on the other hand, is about creation.** It\\'s about building AI that can produce things that resemble human creativity and output, such as:\\n\\n* **Text:** Writing articles, poems, code, scripts, emails, chat responses, and more.\\n* **Images:** Creating realistic photos, artwork, illustrations, logos, and even manipulating existing images.\\n* **Audio:** Generating music, speech, sound effects, and voiceovers.\\n* **Video:** Producing animations, short clips, and even attempting to create longer video content (though this is still developing).\\n* **3D Models:** Designing objects, characters, and environments for games, virtual reality, and design purposes.\\n* **Code:** Writing software code in various programming languages.\\n* **Data:**  Generating synthetic datasets for training other AI models or for simulations.\\n\\n**Here\\'s a breakdown of the key aspects of GenAI:**\\n\\n* **Learning from Data:** GenAI models are typically trained on massive datasets of existing content (text, images, audio, etc.). They learn the patterns, structures, and styles within this data.\\n* **Generating New Content:** Once trained, these models can generate new content that resembles the data they were trained on.  They don\\'t just copy and paste; they create *novel* outputs based on learned patterns.\\n* **Variety of Techniques:** GenAI utilizes various techniques, but some of the most prominent include:\\n    * **Large Language Models (LLMs):**  Like GPT-3, GPT-4, and LaMDA, these are used for generating text, code, and even translating languages.\\n    * **Diffusion Models:**  Popular for image generation (like DALL-E 2, Stable Diffusion, Midjourney), these models work by reversing a process of adding noise to images to create new ones.\\n    * **Generative Adversarial Networks (GANs):**  These involve two neural networks competing against each other (a \"generator\" and a \"discriminator\") to create increasingly realistic outputs, particularly in images and videos.\\n    * **Variational Autoencoders (VAEs):** These learn compressed representations of data and can generate new samples by sampling from this compressed space.\\n* **Prompt-Based:**  Many GenAI models are \"prompt-based.\" This means you provide a textual prompt, instruction, or context, and the model generates content based on that prompt.  For example, you might prompt an image GenAI with \"a photo of a cat wearing sunglasses riding a unicorn\" and it will create an image based on that description.\\n\\n**Why is GenAI important and impactful?**\\n\\n* **Democratization of Creativity:** GenAI tools can empower individuals who may not have traditional skills in art, writing, or music to create content.\\n* **Automation and Efficiency:** GenAI can automate content creation tasks, saving time and resources for businesses and individuals.\\n* **New Forms of Expression:** GenAI opens up new possibilities for creative expression and artistic exploration.\\n* **Problem Solving and Innovation:** GenAI can be used for tasks like designing new products, generating ideas, and even accelerating scientific discovery.\\n\\n**However, it\\'s also important to be aware of the limitations and ethical considerations of GenAI:**\\n\\n* **Accuracy and Factuality:** GenAI models can sometimes generate incorrect or nonsensical information, especially in text generation.\\n* **Bias:** GenAI models can inherit biases from their training data, leading to outputs that reflect societal prejudices.\\n* **Copyright and Ownership:**  Questions arise about who owns the copyright to content generated by AI.\\n* **Misinformation and Deepfakes:** GenAI can be used to create realistic fake images, videos, and text, which can be used for malicious purposes.\\n* **Job Displacement:** There are concerns about the potential for GenAI to automate tasks currently performed by human creatives.\\n\\n**In summary, GenAI is a powerful and rapidly evolving field of AI that is transforming how we create and interact with content. It has immense potential for good, but also requires careful consideration of its ethical and societal implications.**'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "def generate_text(prompt):\n",
    "    client = genai.Client(api_key=API_KEY, http_options={'api_version': 'v1alpha'})\n",
    "    text = \"\"\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model='gemini-2.0-flash-thinking-exp', contents=prompt\n",
    "    ):\n",
    "        for part in chunk.candidates[0].content.parts:\n",
    "            if not part.thought:\n",
    "                text += part.text\n",
    "    return text\n",
    "\n",
    "generate_text(\"What is genAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2024, 10, 31)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date_str = \"2024-10-31T00:08:00Z\"\n",
    "date_obj = datetime.strptime(date_str, \"%Y-%m-%dT%H:%M:%SZ\")  # Parse full datetime\n",
    "date_only = date_obj.date()  # Extract only the date part\n",
    "\n",
    "date_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2024, 10, 31)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = \"2024-10-31\"\n",
    "datetime.strptime(start, \"%Y-%m-%d\").date()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_only == start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2024, 10, 31)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = \"2024-10-31\"\n",
    "datetime.strptime(start, \"%Y-%m-%d\").replace(tzinfo=timezone.utc).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
